from multiprocessing import Pool, Process
import pexpect
import requests
import signal
import time
import logging
import logging.config
from util import *
from config import Config


def _exploit(exploit, target, logger):
    # Spawn the exploit
    p = pexpect.spawn(exploit)

    # Kill the spawned exploit on timeout
    signal.signal(signal.SIGALRM, lambda sig, frame: p.terminate())

    # After the specified seconds the exploit will be killed
    signal.alarm(get_exploit_timeout(exploit))

    # While the exploit is running read a flag as soon as it gets printed to stdout
    while p.isalive():
        flag = p.readline().decode().strip()
        if flag != '':

            # We use this loop to prevent flags not being submitted and stored in the database
            # there is probably a nicer way to do this with requests timeouts and/or retries.
            sent = False
            while not sent:
                try:
                    requests.post(Config.Backend.WebService.url_submit,
                                  data={'flag': flag, 'exploit': exploit, 'target': target, 'timestamp': time.time()},
                                  headers={'Connection': 'close'})
                    sent = True
                except:
                    time.sleep(0.5)
                    logger.error('local connect error')
                    pass

    # If the script prints flags faster then us reading them there might be some flags left on the stdout
    # using readlines() when the process is still running is blocking, now it's safe to use
    output = p.readlines()
    flags = [f.decode().strip() for f in output if f.decode().strip() != '']
    if len(flags) > 0:
        sent = False
        while not sent:
            try:
                requests.post(Config.Backend.WebService.url_submit_many,
                              json={'flags': flags, 'exploit': exploit, 'target': target, 'timestamp': time.time()})
                sent = True
            except:
                time.sleep(0.5)
                # TO DO Logging module
                print('local connect error')
                pass

    # Disable the alarm
    signal.alarm(0)


# Default exploiter class
# Uses multiprocessing (should bypass GIL restrictions)
class Exploiter:
    @staticmethod
    def run(logger):
        while 1:
            time_start = time.time()
            pool = Pool(Config.Exploiter.PoolSize)
            exploits = get_exploits()
            targets = get_targets()
            for exploit in exploits:
                for target in targets:
                    pool.apply_async(_exploit, (exploit, target, logger))
            # Prevents any more tasks from being submitted to the pool.
            # Once all the tasks have been completed the worker processes will exit.
            pool.close()

            # Wait for exploits to finish
            pool.join()
            logger.info('All processes ended in %d seconds' % int(time.time() - time_start))
            input()

    @staticmethod
    def start(logger):
        logger.info('Starting exploiter')
        Process(target=Exploiter.run, args=(logger,)).start()


if __name__ == '__main__':
    logging.config.fileConfig(fname='log.conf')
    logger = logging.getLogger('exploiter')
    Exploiter.start(logger)
